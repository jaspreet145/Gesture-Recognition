{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from keras.models import Model , Sequential\n",
    "from keras.layers import Input, Conv3D , MaxPooling3D , Dropout, Activation, Flatten , Dense , BatchNormalization\n",
    "import re\n",
    "\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "\n",
    "path = '/floyd/input/data'\n",
    "data = []\n",
    "target = []\n",
    "\n",
    "for i in os.listdir(path):\n",
    "    cap = cv2.VideoCapture(os.path.join(path,i))\n",
    "    video = []\n",
    "    label = int(re.sub('.mp4$','',i))\n",
    "    target.append([label])\n",
    "    while(cap.isOpened()):\n",
    "        ret , frame = cap.read()\n",
    "        if(ret == False):\n",
    "            break\n",
    "        frame = cv2.resize(frame , (60,60))\n",
    "        frame = frame.astype(float)\n",
    "        video.append(frame)\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    video = np.array(video)\n",
    "    data.append(video)\n",
    "    \n",
    "data = np.array(data)\n",
    "target = np.array(target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets take 60 frames from all frames with uniform distance\n",
    "extract = []\n",
    "for i in data:\n",
    "    d = len(i)//60;\n",
    "    video = []\n",
    "    for j in range(0,len(i)):\n",
    "        video.append(i[j])\n",
    "        j+=d;\n",
    "        if(len(video)==60):\n",
    "            break\n",
    "    extract.append(video)\n",
    "\n",
    "data = np.array(extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66, 60, 60, 60, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = keras.utils.to_categorical(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66, 66)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_29 (Conv3D)           (None, 60, 60, 60, 6)     1158      \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 60, 60, 60, 6)     24        \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 60, 60, 60, 6)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_30 (Conv3D)           (None, 57, 57, 57, 6)     2310      \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 57, 57, 57, 6)     24        \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 57, 57, 57, 6)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_15 (MaxPooling (None, 28, 28, 28, 6)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_31 (Conv3D)           (None, 28, 28, 28, 12)    1956      \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 28, 28, 28, 12)    48        \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 28, 28, 28, 12)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_32 (Conv3D)           (None, 25, 25, 25, 6)     4614      \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 25, 25, 25, 6)     24        \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 25, 25, 25, 6)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_16 (MaxPooling (None, 8, 8, 8, 6)        0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 3072)              9440256   \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 66)                202818    \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 66)                0         \n",
      "=================================================================\n",
      "Total params: 9,653,232\n",
      "Trainable params: 9,653,172\n",
      "Non-trainable params: 60\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "'''define model'''\n",
    "in_shape = (60 , 60 , 60 , 3)\n",
    "model = Sequential()\n",
    "model.add(Conv3D(6, (4, 4 , 4), padding='same', input_shape=in_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv3D(6,(4, 4 , 4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling3D(pool_size = (2,2,2)))\n",
    "\n",
    "\n",
    "model.add(Conv3D(12 , (3, 3 , 3) , padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv3D(6,(4,4 , 4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling3D(pool_size = (3,3 , 3)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3072))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(66))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy' , optimizer = opt , metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "66/66 [==============================] - 5s 74ms/step - loss: 6.4761 - acc: 0.0000e+00\n",
      "Epoch 2/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 13.1863 - acc: 0.0152\n",
      "Epoch 3/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 7.0587 - acc: 0.0455\n",
      "Epoch 4/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 6.2701 - acc: 0.0606\n",
      "Epoch 5/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 5.9724 - acc: 0.0455\n",
      "Epoch 6/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 5.3249 - acc: 0.1515\n",
      "Epoch 7/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 5.1454 - acc: 0.0455\n",
      "Epoch 8/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 4.8390 - acc: 0.1667\n",
      "Epoch 9/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 4.3560 - acc: 0.0909\n",
      "Epoch 10/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 4.2389 - acc: 0.1364\n",
      "Epoch 11/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 4.3131 - acc: 0.2273\n",
      "Epoch 12/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 3.8881 - acc: 0.4545\n",
      "Epoch 13/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 4.0914 - acc: 0.1364\n",
      "Epoch 14/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 3.6327 - acc: 0.3182\n",
      "Epoch 15/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 4.0237 - acc: 0.1667\n",
      "Epoch 16/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 3.3028 - acc: 0.2273\n",
      "Epoch 17/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 3.1560 - acc: 0.4848\n",
      "Epoch 18/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 2.8592 - acc: 0.4697\n",
      "Epoch 19/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 3.0850 - acc: 0.3636\n",
      "Epoch 20/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 2.3534 - acc: 0.5606\n",
      "Epoch 21/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 2.3618 - acc: 0.5303\n",
      "Epoch 22/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 3.1920 - acc: 0.3333\n",
      "Epoch 23/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 2.0836 - acc: 0.4848\n",
      "Epoch 24/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 1.6966 - acc: 0.5909\n",
      "Epoch 25/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 1.9845 - acc: 0.5303\n",
      "Epoch 26/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 2.9738 - acc: 0.3485\n",
      "Epoch 27/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 0.9915 - acc: 0.9394\n",
      "Epoch 28/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 1.2918 - acc: 0.6667\n",
      "Epoch 29/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 1.2631 - acc: 0.7121\n",
      "Epoch 30/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 0.7909 - acc: 0.8788\n",
      "Epoch 31/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 0.7753 - acc: 0.8485\n",
      "Epoch 32/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 3.1540 - acc: 0.3030\n",
      "Epoch 33/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 2.3058 - acc: 0.5909\n",
      "Epoch 34/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 1.0674 - acc: 0.7121\n",
      "Epoch 35/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 0.6468 - acc: 0.9242\n",
      "Epoch 36/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 1.7327 - acc: 0.5455\n",
      "Epoch 37/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 0.8301 - acc: 0.8788\n",
      "Epoch 38/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 0.7698 - acc: 0.8939\n",
      "Epoch 39/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 1.7968 - acc: 0.5606\n",
      "Epoch 40/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 0.8696 - acc: 0.7576\n",
      "Epoch 41/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 1.0203 - acc: 0.7273\n",
      "Epoch 42/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 0.7754 - acc: 0.8485\n",
      "Epoch 43/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 0.4426 - acc: 0.9545\n",
      "Epoch 44/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 0.3351 - acc: 0.9848\n",
      "Epoch 45/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 0.3023 - acc: 0.9848\n",
      "Epoch 46/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 0.2980 - acc: 0.9848\n",
      "Epoch 47/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 0.5169 - acc: 0.9091\n",
      "Epoch 48/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 0.5524 - acc: 0.9091\n",
      "Epoch 49/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 0.4030 - acc: 0.9545\n",
      "Epoch 50/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 0.3041 - acc: 0.9848\n",
      "Epoch 51/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 0.3096 - acc: 0.9697\n",
      "Epoch 52/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 0.2688 - acc: 0.9848\n",
      "Epoch 53/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 0.2652 - acc: 0.9848\n",
      "Epoch 54/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 0.2921 - acc: 0.9848\n",
      "Epoch 55/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 0.3033 - acc: 0.9697\n",
      "Epoch 56/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 0.2793 - acc: 0.9848\n",
      "Epoch 57/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 0.2647 - acc: 0.9848\n",
      "Epoch 58/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 0.6946 - acc: 0.8030\n",
      "Epoch 59/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 0.5199 - acc: 0.9697\n",
      "Epoch 60/60\n",
      "66/66 [==============================] - 3s 40ms/step - loss: 0.5126 - acc: 0.9697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f761266d438>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data , target , epochs = 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred  = model.predict(data)\n",
    "cnt= 0\n",
    "for i in range(len(pred)):\n",
    "    if(target[i].argmax() == pred[i].argmax()):\n",
    "        cnt+=1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
